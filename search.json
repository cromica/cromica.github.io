{"entries":[{"title":"Why a blog","url":"/blog/2014/02/23/why-a-blog.html","date":"2014-02-23 22:54:21 +0200","categories":["blog"],"body":"I was thinking to start a blog for some while but never find the right time. There are lots of ways to share information and knowledge but blog allows to share information in detail and also provide thorough explanations. Besides this I intend to use it as a personal knowledge base. Quite often I realize that I've done something similar in the past but I can't remember or find the information. So finally here it is. The Journey There are quite a few things to think about when deciding to have a blog, like: What will I write about? What blogging platform should I use? Since I'm a developer should I build something of my own? Where I will host it? What's the design of the blog ? There some other smaller things but those where the main questions for me. For the first one I've answered in the first paragraph but let's see a bit about the other questions. First of all I'm not a big Wordpress fan although I've used it in the past. This is not because it's bad rather it's a mater of taste. Next I had a look at Ghost which is really interesting and nice. There are some other good blogging platforms like Blogger or Tumblr and I have to admit that it's hard to decide between them but I wanted to have more control so just a blogging platform was a no go for me. Building something of my own was interesting enough but I quickly realize that I don't have enough time to do it so I abandoned the idea. Looking for other option I read David Ebbo was moving his site to Github pages and decided to have a look. I really liked the way Github pages is working and I will tell more about this on future posts. So at this point my blog is hosted by Github pages and this is just the first version of it. I will add some other features in the next weeks. "},{"title":"Why I choose Github pages","url":"/blog/2014/02/24/why-i-choose-github-pages.html","date":"2014-02-24 23:52:21 +0200","categories":["blog"],"body":"Github pages is something I've recently heard of and I really like it from the begging although I didn't exactly knew how is working. The main idea is that you will use a github repository to serve your site or blog. Main benefits For me these are the main benefits in using github pages: I have complete control of my site not being constrained in any way by a blogging platform. No database is involved since github pages will serve only static html. Pages will be produced using Jekyll (more on this in future post). It's completely free so I don't need to bother looking for hosting options. And it has very good performance . It uses markdown for create and edit posts. Beside that github offers in-browser support for markdown which means that I can create or edit posts directly from browser. Since github pages uses github repositories it means that anyone can contribute to the website by sending a pull request . So please fell free to send any changes or if you see any spelling errors you can directly correct them, all you need to do is go to the repository and submit a pull request . If anyone has any suggestions on various features I can add or any changes please let me know by creating an issue or drop me a line . I really like github pages because it's very simple to use and it's emphasizes collaboration so anyone can become a contributor to the blog. "},{"title":"The engine behind my blog","url":"/blog/2014/03/03/the-engine-behind-my-blog.html","date":"2014-03-03 23:52:21 +0200","categories":["blog"],"body":"I guess it's time to dive a bit more on what technology stands behind my blog. In the previous posts I've talked about the reasons to start a blog , why I choose github pages to host it and now I will talk about Jekyll, the engine behind my blog. What is Jekyll ? Jekyll is a parsing engine which generates static html pages from dynamic components like template or markdown files. It uses a simple inline syntax which at build time is evaluated and replaced resulting a static page. Here is a short and very simple example: <meta http-equiv= \"Content-type\" content= \"text/html; charset=utf-8\" /> <title> {{ page.title }} </title> In the above example the value for the title tag will be set with the value of the title property of the page object. Jekyll has a simple and limited syntax so it's quit easy to learn it, but it has great flexibility with lots of options on how to build the site. Also you can have partial files which Jekyll will combine at build time. Jekyll has a special folder structure which is used in order to generate the static website: _includes folder is used to define partial files which can then be added to various pages. Some possible partial files might be the footer or header which for sure will be nice to define in one place and use on all pages. _layout folder is pretty self explanatory and is the location where you will define the layouts of your pages. _posts folder is the location from where dynamic content/posts will be saved. Jekyll uses a markup language like Markdown for this kind of files. _drafts folder is where the working in progress stuff will be held since this location will not be evaluated at build unless --draft is specified. _site folder is the location from where Jekyll will serve the static pages. During the build process Jekyll will combine partial files and evaluate the syntax producing a static html file which will be saved in this folder. Jekyll and Github pages Jekyll can be installed locally and since it has a small static webserver embedded it can be used in lots of ways to serve the website. Using jekyll serve you can build and browse the site. Beside this option you can use the site developed with Jekyll directly with Github pages since behind the scenes it uses Jekyll. So all you have to do is push your site developed with jekyll to a repository and Github will do the trick almost instant. Please be aware that this is not true for all Github repositories, it's only valid for Github pages repositories which must be created according to this steps . My intention with this article was to give a high overview of what Jekyll means and some basic principles. If you are looking for more details please have a look here and here . If you have any questions please don't hesitate and leave a comment. "},{"title":"Install Jekyll using Chocolatey","url":"/jekyll/2014/03/06/install-jekyll-using-chocolatey.html","date":"2014-03-06 21:14:00 +0200","categories":["jekyll"],"body":"As you probably already know this website and blog are created using github pages which behind the scene uses Jekyll. More on this you can read on my blog post .Every time I write a new article or make a change I would like to preview it before publishing it to live website.When this get published to my website repository, Github builds it almost instantly so I'm able to see my change really fast, but this is still done on the public website. This can work pretty well but I prefer to see my changes locally and only if I'm ok to publish them on my repository . So in order to do that I need to install jekyll on my local machine and use `jekyll serve` to build and serve the website. Install Jekyll on a Windows machine Jekyll is build with Ruby and uses some Python libraries so we need to install them in order to run Jekyll. Since most the work I do is around Microsoft .Net platform I need to use Windows operating system . My source of inspiration was this article by David Ebbo. In his artcile he points to this article which explains all the steps in detail. The information is perfectly valid at this moment so you can follow that too but I would like to show you a simple way using Chocolatey . The steps are pretty much the same with the article, the only difference is in the way you install the applications. What is Chocolatey ? Chocolatey is a global PowerShell execution engine using the NuGet packaging infrastructure. Think of it as the ultimate automation tool for Windows. It is very simple to install Chocolatey you just have to run this script on your command prompt: @powershell -NoProfile -ExecutionPolicy unrestricted -Command \"iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET PATH = % PATH %; % systemdrive %\\ chocolatey \\ bin If this doesn't work for you there are other ways to install chocolatey here . Now that we have chocolatey installed we can open a command prompt and using cinst we can install what we need. Install Ruby Run the following command on the command prompt: cinst ruby To check if it was installed with success close then open a new command prompt and run: ruby --version Install Ruby Devkit Here are the steps required to install and configure Devkit: cinst ruby2.devkit Initialize and configure by updating config.yml file from the devkit folder. In the command prompt type the following: cd \"C:\\DevKit2\" ruby dk.rb init notepad config.yml This will open notepad where you need to add - C:\\tools\\ruby200 at the end of the file. This path represents the location where ruby was installed and it might be different than the one I've specified. After this step you need to go back to the command prompt and install gem : ruby dk.rb review ruby dk.rb install At this point you should have gem installed. You can check it this way: gem --version If it's not working try to close and then open a new command prompt. Install Jekyll Run the following command on the command prompt: gem install jekyll What is Pygments ? Pygments is a generic syntax highlighter for general use in all kinds of software such as forum systems, wikis or other applications that need to prettify source code. Pygments is written in python so we need to install Python Install Python Run the following command on the command prompt: cinst python2 Run the following command in a new command prompt to verify installation: python --version Install 'Easy Install' Easy Install is a mechanism similar with ruby gems or chocolatey for python packages. In order to install it follow the steps: 1.Download ez_setup.py 2.Run the following command from the location where you saved ez_setup.py python ez_setup.py 3.Set the 'Python Scripts' directory (e.g. C:\\tools\\python2\\Scripts ) to PATH 4.Verify that easy_install is installed properly: easy_install --help Install Pygments Now that we have python and easy install all we just need to run the following commnad to install pygments: easy_install pygments Start Jekyll You can now create a new Jekyll blog which can be browsed on localhost:4000 : jekyll new myblog cd myblog jekyll serve I found it much easier to install all this using Chocolatey. I'm keen to get your feedback on this. "},{"title":"My Journey to start a blog","url":"/blog/2014/03/15/my-journey-to-start-a-blog.html","date":"2014-03-15 09:40:00 +0200","categories":["blog"],"body":"Now that I written some articles around my journey to start a blog I think it might be very useful to have a short summary of my journey. The Journey Well I was thinking to start a blog for sometime because of the reasons I've pointed in my first article Why a blog ? . This is a technical blog since I will write most of the time about software development and various technologies in an attempt to share my knowledge and experience but also because I want to us it as a brain dump. From time to time I might write about some other things but probably still around technology. Finally this year I started looking for various options to host a blog and I ended up using Github pages . Why I made this option I've detailed in my blog post Why I choose Github pages . Github pages is powered by a very nice and interesting framework called Jekyll for which I wrote an introduction in my article The engine behing my blog . Since my work is most of the time in Microsoft world I had to install Jekyll on Windows which is not necessarily straight forward so I described an easier alternative using chocolatey in my article Install Jekyll using chocolatey . I'm really glad that finally I manage to start this blog but I guess the real challenge comes now when I will need to actually use it and keep it alive. I hope you will find my journey useful to decide start a blog or if you are already decided to assist in your steps to get the blog started. "},{"title":"Thank you Endava","url":"/career/2014/09/20/thank-you-endava.html","date":"2014-09-20 21:53:00 +0300","categories":["career"],"body":" This week I had my last day as an Endava employee since I've accepted a new challenge, but more about that in a later post. Endava is a company that constantly tries to improve based on previous experiences and feedback so last week I had brief exit interview which is meant to provide feedback to the company. I have to admit that I really enjoyed this last discussion where I had one last opportunity to directly share my ideas with Endava. My journey with Endava was about 7 years and a half. All this years had a great impact on my career and who am I today. When I joined the company I was a naive developer who was just interested in writing some code but slowly that changed because the company was constantly taking care of my growth and career path. I really think that Endava provides a great working environment where you can learn, grow and expand your skills regardless of the fact that you are just starting your career or you have several years of experience. Certainly I will miss my colleagues from Endava with which I shared so many great experiences, but I'm still going to be around so don't be a stranger suddenly. I want to thank you all for your great support and help during all this years. But because I'm leaving it doesn't mean that we can't stay in touch. For sure I'm going to post more often on this blog so you can leave a comment or find me on Twitter, Linkedin, Facebook, Gmail. Thanks Endava for all this great years. "},{"title":"Hello SDL","url":"/career/2014/10/01/hello-sdl.html","date":"2014-10-01 17:15:00 +0300","categories":["career"],"body":" I now have two weeks since I joined SDL as a Language Platform Evangelist Developer . Almost everyone asked me what does that mean and what will I do so I decided that I better explain here in detail. If you are looking for a general definition of the position you can find one on wikipedia but it won't help you too much. In order to understand it better you really need to understand the context. Who is SDL? First off all let me tell you a few words about SDL and what is the company doing. It started as language translation service company and quickly become also a company providing software for language translation. For many years this was the only domain where SDL activated but new interesting opportunities arise and the company made new acquisitions on domains like e-commerce, social media monitoring, web content management, analytics and so on. All this new products allowed SDL to re-position itself recently as a global customer experience management company. If you are looking for more details please have a look here for the history of the company and here for the new vision and mission. What I'm going to do at SDL? As I previously said SDL is offering now global customer experience management and as you might already think when you say global you immediately think of multiple languages, which means translation. I'm going to be closely involved in SDL Trados Studio and Language Cloud and probably some other products depending on the needs. Most of my work will be around creating and growing the development community for this products, but I will also offer support and consultancy to clients and help the sale process when is necessary. Growing the development community can mean many things but here are some of they key things I will do: Explain better the current Studio API's and in what product areas it can be used. Improve and simplify the current API based on community and clients feedback. Contribute to the new Language Cloud SDK. Simplify how we can use develop against the API's. The most important bit will be to have them open to all possible developers. Speak at developer conferences and discuss about the API's and SDK's. If you have any suggestion or you want me at a conference just leave a comment. Contribute and help develop the new community platform which we will launch in the near future. Develop plugins based on customer needs. This will also act as examples for other developers. I think this is very interesting and I'm really keen to see how things will evolve since there are many other things that I would like to do as part of my new role. Also SDL has some interesting plans around the community so stay tuned. "},{"title":"Codecamp 2014","url":"/speaker/2014/10/31/Codecamp-2014.html","date":"2014-10-31 11:07:00 +0200","categories":["speaker"],"body":" One of my personal objectives for this year was to attend as a speaker to local community developer conferences. Most known,at least by me, are ITCamp and Codecamp. ITCamp is held once a year in Cluj-Napoca and Codecamp is held twice a year in Iasi, although there are some smaller Codecamp events in Cluj those are not related. I'm really happy that this year I had the opportunity to participate at all 3 events, so a big big thanks to the organizers for having me. Codecamp I've never been to Iasi until this year and I can't say that I've seen too much of it since both times I've been there I was caught up with Codecamp event. Although I've haven't seen much of the city I've met really nice people which are really passionate about software industry. Each event had more than 1400 participants which I believe it's a really big achievement. The fact that there is no fee to participate at the conference opened the door even to students which had a great opportunity to get in touch with the industry and basically their future. The event is also for seniors who can find lots interesting topics and a good place to network. For me Codecamp was a nice experience and I can't wait for the next edition which will probably happen in spring 2015. Kudos to Florin Cardasim , Gabriel Enea and Dan Nicola who believed in their ideas and made this possible. My sessions I had two session which I presented this year at Codecamp . The first one which I've done in may is Information Exchange using Hybrid Azure Integration . In this session I'm talking about ways we can integrate on-premise LOB applications with azure cloud solutions based on messaging pattern. The second session which I had last weekend is Click'n'Deploy . This one was done together with Radu Pascal and it was my first duet session. In this talk we present our approach on enabling continuous integration and continuous deployment using TFS Build , Gulp and Octopus Deploy . During the session we showed how we've implemented it in a real life example. If want to see more pictures have a look here . Information Exchange using Hybrid Azure Integration slides Click'n'Deploy slides Please leave a comment if you have any questions or feedback. If you are interested in presenting this sessions just send me an email. "},{"title":"3rd party assemblies and SDL Studio plugins","url":"/sdl%20studio/2014/11/07/3rd-party-assmeblies-and-SDL-Studio-plugins.html","date":"2014-11-07 18:18:00 +0200","categories":["sdl studio"],"body":" Last week I was working at a new plugin for SDL Studio 2014 and I wanted to serialize some information in json. The best tool handle this type of operations in .NET, at least in my opinion, is Json.NET . It made perfect sense to use it but until now I didn't use any external dependencies in an SDL Studio plugin so I started to look into what options we have to deploy our plugins together with 3rd party assemblies. SDL Studio plugins This is not a detailed look at what SDL Studio plugins are but I want to give a bit of context on how they are working. First of all each plugin has to be packed in a package with extension .sldplugin (this a zip file in essence). If you use the SDL Studio templates from Visual Studio this done for you automatically. Once you have the package you need to deploy it in one of the three location where SDL Studio is expecting plugins: $(CurrentUser)\\AppData\\Local\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Packages\\ $(CurrentUser)\\AppData\\Roaming\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Packages\\ $(ProgramData)\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Packages\\ There is no difference between this locations so you can choose whatever you prefer. Once the package is in one of this locations when SDL Studio starts it will unpack the package, drop the content into a dedicated location and load the plugin assembly. This depends on where you deployed your package and can be one of this locations: $(CurrentUser)\\AppData\\Local\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Unpacked\\ $(CurrentUser)\\AppData\\Roaming\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Unpacked\\ $(ProgramData)\\SDL\\SDL Trados Studio{Studio Version}\\Plugins\\Unpacked\\ Deploy 3rd party assemblies Now that we have a brief understanding on how SDL Studio handles plugins let's see what options we have to deploy 3rd party plugins: Include the assemblies in the plugin package Create an installer which will copy the 3rd party assemblies into SDL Studio folder under $(ProgramFiles) Although the second option can work I don't like it because it requires more work, administrative rights to deploy the assemblies and might intefere with Studio installation. This was also suggest by David Fritch in this thread as a possible way to do it. I consider the first option the right way to do it since it's very simple and clean. All you have to do is change the pluginpackage.manifest.xml which has to be part of the solution in order to generate the .sdlplugin file. By default this xml file contains some tags to specify the plugin name, version, description, author and required SDL Studio product. You will need to add an <Include> tag which in my case, for Json.NET , looked something like this: <Include> <File> Newtonsoft.Json.dll </File> </Include> You can have a look at my entire xml file here . Please leave a comment if you have any questions or feedback. "},{"title":"SDL Studio standalone plugin assembly resolver","url":"/sdl%20studio/2014/11/28/SDL-Studio-standalone-plugin-assembly-resolve.html","date":"2014-11-28 14:20:00 +0200","categories":["sdl studio"],"body":" SDL Studio plugin system allows developers to develop new features on top of the standard functionality. There are 2 types of plugins that can be developed, one which behaves like a Studio add-in and another one which behaves as a standalone application. Both plugin types require to run inside Studio installation folder. This is because the public Studio SDK is using other assemblies that are located in Studio folder. While this is perfectly fine for add-in type plugins for standalone plugins this adds limitation on where and how you can deploy your application. Why not GAC ? Many developers have asked us to register Studio assemblies in GAC in order to solve the issue on where and how you can deploy your standalone Studio plugins. Having Studio assemblies registered in GAC means that those assembly can be shared across the entire system. Although registering assemblies in GAC might had seem to be a good solution there are many implications when doing it. The main reason why Studio is not using GAC is because of the following scenario: GAC supports multiple version of an assembly. This means that when an assembly is updated to a newer version both versions will be saved. You might say that the old version should be removed, but this is not always possible since for example there are customers that have multiple version of Studio that are used on the same machine. Keeping multiple version of the same assembly will lead to unexpected behavior and errors from the application. You can read more about why to avoid GAC here . Got it ... no GAC, but we want solutions! To solve this problem I've developed a small library called Studio AssemblyResolver . Basically every time an dll is not found in the current application location the library will look after the dll in the Studio folder. The library comes with 2 mechanism for looking after Studio folder but you can add your own resolve mechanism. If you are interested about more details please have a look here . The library is also published in the Nuget package repository which allows to be easily added to your project. How to use Studio AssemblyResolver There are 2 simple steps to get your Studio assemblies resolved: Add a reference to the Studio.AssemblyResolver library from Visual Studio using NuGet Add the following line of code in you application entry point AssemblyResolver . Resolve (); I've already included the Studio AssemblyResolver library in Reindex Translation Memories plugin. You can have a look here if you are interested to see how I've included the library. Please leave a comment if you have any questions or feedback. "},{"title":"How to access segment tags using Studio File Type Framework","url":"/sdl%20studio/2015/01/06/How%20to%20access%20segment%20tags%20using%20Studio%20File%20Type%20Framework%20.html","date":"2015-01-06 18:20:00 +0200","categories":["sdl studio"],"body":" Accessing segment tags might not be something you have to do everyday but there might be some scenarios where you need to manipulate the tags of your segments. This can be done using Studio File Type Framework which is part of the Studio SDK. The documentation is providing an overview of the entire framework and also includes high level overview of what I'm going to discuss in this article. Visitor Pattern Before jumping into the problem I recommend you to get familiarized with the visitor pattern since this is used as part of the Studio File Type Framework and you will need apply it in order to get the tags. To get familiarized you can read the theory on wikipedia or if you want a practical example you can have a look here . In Studio File Type Framework visitor pattern is made available via IMarkupDataVisitor interface. Paragraphs, Segments and more When a document is opened for translation Studio brakes it into segments. This is done by the segmentation engine using the segmentation rules defined in Studio. A segment can be a paragraph or a sentence length but what is important to understand is that for Studio a segment represents a piece of localizable content for which existing translations can possibly be used. Besides localizable content there are other elements, like formatting, that Studio needs to take into considerations. Now that we have a better understanding of how Studio is handling the content let me highlight how this is reflected in the File Type Framework: IParagraph represents the entire content that is displayed on one Studio editor row. This can contain multiple elements like tags or segments. IParagraphUnit a unit of source language content and the localized target language content. Source and Target can be accessed using the corresponding properties which will return an IParagraph object instance with the information described above. One thing to keep in mind is that there are two type of paragraph units: Structure paragraph units will contain only structure tags that are not localizable. In this case the Target will be null. Localizable paragraph units will contain localizable content. ISegment represents a piece of localizable content. ISegmentPair segments exists in source and target language versions which are bot accessible using ISegmentPair . Segments and Paragraphs are considered containers of other elements like text, comments, revisions and so on. All containers share common behavior and that's why in the File Type Framework both are abstracted using IAbstractMarkupDataContainer . An IAbstractMarkupDataContainer contains multiple IAbstractMarkupData elements. This means that text, comments and other similar elements are represented in the framework using IAbstractMarkupData interface. One very important aspect of this structure is the fact that a segment can be considered as an element of the paragraph but also as a container for other elements which means that it can be manipulated as an IAbstractMarkupDataContainer or as an IAbstractMarkupData . Here's a diagram which describes the structure: Access segment tags All paragraph elements are like a tree structure that must be traversed using visitor pattern. For each paragraph unit we can look at the Source property which is an IParagraph . Thinking at the abstraction I was talking earlier an IParagraph is in essence an IAbstractMarkupDataContainer which in turn is an enumeration of IAbstractMarkupData . Here's a sample code on how you can iterate paragraph unit elements: IEnumerable < IAbstractMarkupData > container = paragraphUnit . Source ; foreach ( var contentItem in container ) { //structure tag is not supported by IMarkupDataVisitor and you should ignore it IStructureTag stag = contentItem as IStructureTag ; if ( stag == null ) continue ; contentItem . AcceptVisitor ( new MarkupDataVisitor ()); } There is one new thing in the above sample which I didn't discuss about.This is MarkupDataVisitor which is an implementation of the interface IMarkupDataVisitor I was mentioning in the visitor pattern section. Here's how the interface looks like: /// <summary> /// Interface for the visitor in the visitor pattern implementation for translatable source / target /// content items in a localizable paragraph unit. /// </summary> public interface IMarkupDataVisitor { /// <summary> /// Called by tag pair instances. /// </summary> /// <param name=\"tagPair\"></param> void VisitTagPair ( ITagPair tagPair ); /// <summary> /// Called by placeholder tag instances. /// </summary> /// <param name=\"tag\"></param> void VisitPlaceholderTag ( IPlaceholderTag tag ); /// <summary> /// Called by text instances. /// </summary> /// <param name=\"text\"></param> void VisitText ( IText text ); /// <summary> /// Called by segment instances. /// </summary> /// <param name=\"segment\"></param> void VisitSegment ( ISegment segment ); /// <summary> /// Called by location marker instances. /// </summary> /// <param name=\"location\"></param> void VisitLocationMarker ( ILocationMarker location ); /// <summary> /// Called by comment marker instances. /// </summary> /// <param name=\"commentMarker\"></param> void VisitCommentMarker ( ICommentMarker commentMarker ); /// <summary> /// Called by other marker instances. /// </summary> /// <param name=\"marker\"></param> void VisitOtherMarker ( IOtherMarker marker ); /// <summary> /// Called by locked content instances. /// </summary> /// <param name=\"lockedContent\"></param> void VisitLockedContent ( ILockedContent lockedContent ); /// <summary> /// Called by revision marker instances. /// </summary> /// <param name=\"revisionMarker\"></param> void VisitRevisionMarker ( IRevisionMarker revisionMarker ); } As you can see you are now able manipulate each element type. For example if you need formatting information you can get it from the ITagPair interface. Don't forget that segments are containers as well so on VisitSegement method you need to traverse his structure in the same way as for the paragraph unit. Please leave a comment if you have any questions or feedback. "},{"title":"Click'n'Deploy Studio plugins","url":"/sdl%20studio/2015/02/13/Click-n-deploy%20Studio%20plugins.html","date":"2015-02-13 01:20:00 +0200","categories":["sdl studio"],"body":" App stores changed the way we install and maintain software on our devices. You now have a single centralized place where you go and search for what you need, click a button and in a matter of minutes you have the app working on your device. In a similar way you can extend SDL Studio by going on OpenExchange store and download a plugin you would like or need. Now this works just fine for most of the Studio plugins or apps but there are situations when you need to develop something that is specific for your company and doesn't make sense to be public to everyone since it's probably irrelevant for them and it might also contain confidential information. It would be nice if you would be able to create your private store inside OpenExchange where you can have you apps centralized and search-able just by you but such a feature is not available at the moment. This article and video is about an alternate solution for this type of scenarios. The solution The solution is very simple and is based on the idea to automate as much as possible the process of releasing you plugin. The exact same thing is promoted by Continuous Delivery practice and together with the evolution of this a couple of release management tools like Octopus Deploy or GO appeared in order to ease the adoption of such a practice. In our case since Studio plugins are developed using Microsoft .Net and it makes perfect sense to use Octopus Deploy since is dedicated for .Net solutions. Of course you can try and use GO or any other release management tool you prefer. If it's not clear by now the solution I'm talking about is to automate your Studio plugin release management using Octopus Deploy . Octopus Deploy I'm not going to cover in detail Octopus Deploy since it comes with a very good documentation, rather I'm going to present a higher level overview of how is going to work with Studio plugins. Octopus comes with a central server component which is called Octopus Deploy Server that you need to install somewhere where all your users machines will be able to access it. It can be an internal private server, a public server or somewhere in a cloud platform, there is no limitation as long as it's accessible. Octopus Deploy Server comes with web user interface which you can use once you have the server installed. Besides the server component Octopus comes with a client component called Tentacle Deploy agent . This has to be installed on each user machine and it will be used to deploy your software, in our case the Studio plugins. This is a one time operation and once it's done you will only use the web user interface that comes with the server. There is a third component called OctoPack that is used to push the software/Studio plugin from you development or build machine to Octopus Deploy Server . Click'n'Deploy Studio plugins There are quit a few moving parts when you first setup Octopus Deploy and some of the steps might not that obvious so instead off writing them in this article I decided that it would be better if just create a video to show you exactly how you configure Octopus to release Studio plugins to the user machine. Useful learning resources: Octopus Deploy Getting Started Installing Octopus Deploy Server Installing Tentacles Using OctoPack What is Nuget? Develop SDL Studio plugins Please leave a comment if you have any questions or feedback. "},{"title":"Sdl Studio PowerShell toolkit is now open source","url":"/sdl%20studio/2015/02/18/Sdl-Studio-PowerShell-toolkit-open-source.html","date":"2015-02-18 21:20:00 +0200","categories":["sdl studio"],"body":" Starting from today Sdl Studio powerhsell toolkit is open source and you can find it on github. The toolkit was written to facilitate scripting of the Project Automation API which comes with SDL Studio. Until now this was kept on the SDL internal TFS and you where only able to get it by going to the community forum. At this point you might ask yourself what's going to change from now on since the toolkit was freely distributed until now? Github The project is now hosted on github in this location . The internal TFS will no longer be used so this means that every change that will be made to the toolkit will be made on this repository including changes done by Sdl developers. Also this allows any interested developer to contribute to the toolkit. Public releases are also hosted on github and you can be find them here . You are now able to download the entire toolkit or just one of the modules. Open source Open source it's not at all equal to free, it's much more than that. Yes you don't have to pay any money for this toolkit but from now on is not only Sdl's responsibility to maintain this toolkit, it's also the responsibility of each toolkit user or developer. To be a bit more specific if you find bug or want a new feature you can log it here but don't necessarily expect someone from Sdl to resolve the issue, it might be anyone from the community or even you. Another important aspect that comes with open source is that every change you made to this toolkit has to be made open source. It's not mandatory to be made in the same repository but it has to be open source. I would encourage everyone to contribute to this repository and make the resolved issues available to everyone. Conclusion Contribute to Sdl Studio PowerShell toolkit from here or download the latest release from here . Please leave a comment if you have any questions or feedback. "},{"title":"Merge files using SDL Studio Project Automation API","url":"/sdl%20studio/2015/03/11/Merge-translatable-files-using-SDL-Studio-Project-automation-api.html","date":"2015-03-11 21:20:00 +0200","categories":["sdl studio"],"body":" SDL Studio allows the user to merge multiple files into one bilingual document (sdlxliff). This can be done during project creation and it can be useful in situations where you have multiple small files and you might want to translate them in one go without switching between documents. If you don't already know SDL Studio is very extensible via the API's that are made available but sometimes simple things are not so simple to do by code because of software design decision or technical limitations. Merging files using SDL Studio Project Automation API can be done but is not that straight forward as you might expect and this is why I decided to write this article to show how this is done. Create Merged Project File Looking at the documentation you can easily find CreateMergedProjectFile method which allows you to specify the files you want to be merged and the name of the bilingual file which must have \".sdlxliff\" extension. At this point this seems to be very simple but when you run this method you realize that is not actually doing much, there is no visible result on the project and the status is Not Merged . What am I missing? At this point you only get an MergedProjectFile object which is just a representation of the merging structure. In order to actually create the bilingual merged file we need to use Studio File Type Framework to generate the sdlxliff file. Once we have that we can use CopyToTargetLanguages to copy the merged files to all target languages we need. To make this even more clear and concrete I'm going to share a sample code that is doing all the steps I've described until now. Conclusion It's not that complicated to merge files using the SDL Studio API but is not obvious and intuitive. I hope this article will clarify this situation. Please leave a comment if you have any questions or feedback. "},{"title":"Code by the book","url":"/career/2015/04/19/2015-04-19-Code-by-the-book.html","date":"2015-04-19 22:20:00 +0300","categories":["career"],"body":" SDL Studio allows the user to merge multiple files into one bilingual document (sdlxliff). This can be done during project creation and it can be useful in situations where you have multiple small files and you might want to translate them in one go without switching between documents. If you don't already know SDL Studio is very extensible via the API's that are made available but sometimes simple things are not so simple to do by code because of software design decision or technical limitations. Merging files using SDL Studio Project Automation API can be done but is not that straight forward as you might expect and this is why I decided to write this article to show how this is done. Create Merged Project File Looking at the documentation you can easily find CreateMergedProjectFile method which allows you to specify the files you want to be merged and the name of the bilingual file which must have \".sdlxliff\" extension. At this point this seems to be very simple but when you run this method you realize that is not actually doing much, there is no visible result on the project and the status is Not Merged . What am I missing? At this point you only get an MergedProjectFile object which is just a representation of the merging structure. In order to actually create the bilingual merged file we need to use Studio File Type Framework to generate the sdlxliff file. Once we have that we can use CopyToTargetLanguages to copy the merged files to all target languages we need. To make this even more clear and concrete I'm going to share a sample code that is doing all the steps I've described until now. Conclusion It's not that complicated to merge files using the SDL Studio API but is not obvious and intuitive. I hope this article will clarify this situation. Please leave a comment if you have any questions or feedback. "}]}